{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TemplateMaker003\n",
    "\n",
    "This is a simple spectral masking (cross-correlation) based approach. We extract and generate a template, and then cross-correlate with peak detection. We export the template and the parameters used to a .h (header file) for export on the CARACAL ARM M4F board.\n",
    "\n",
    "We use this to generate and test out some new templates that will work better on the nepal data (hopefully)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_SR = 8000 # Target sampling rate\n",
    "SPECD_FFT_LEN =  512 # Real FFT length (in the M4F - we use double of this on the PC as we don't do single-sided)\n",
    "ML_BIN_AGG = 8 # Number of bins\n",
    "ML_FLO = 800 # Low freq\n",
    "ML_FHI = 950 # High freq\n",
    "ML_FFT_STRIDE = 256 # Stride\n",
    "FILEPREFIX = \"templateMaker003_001\" # what to save the output files as\n",
    "THRESHOLDED = False # Threshold the template or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import pylab\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amogh\\AppData\\Local\\Temp\\ipykernel_1136\\1340527391.py:7: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  aud,sr = librosa.load(filename,sr=ML_SR)\n",
      "C:\\Users\\Amogh\\anaconda3\\envs\\internship1\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\CloudData\\\\2024\\\\Nepal\\\\ML001\\\\20h00.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\internship1\\Lib\\site-packages\\librosa\\core\\audio.py:176\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__soundfile_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sf\u001b[38;5;241m.\u001b[39mSoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\internship1\\Lib\\site-packages\\librosa\\core\\audio.py:209\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\internship1\\Lib\\site-packages\\soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    657\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\internship1\\Lib\\site-packages\\soundfile.py:1216\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1215\u001b[0m     err \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_error(file_ptr)\n\u001b[1;32m-> 1216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode_int \u001b[38;5;241m==\u001b[39m _snd\u001b[38;5;241m.\u001b[39mSFM_WRITE:\n\u001b[0;32m   1218\u001b[0m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[0;32m   1219\u001b[0m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
      "\u001b[1;31mLibsndfileError\u001b[0m: Error opening 'C:\\\\CloudData\\\\2024\\\\Nepal\\\\ML001\\\\20h00.wav': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m endT \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m539\u001b[39m\n\u001b[0;32m      5\u001b[0m gtT \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1.0\u001b[39m,\u001b[38;5;241m12.4\u001b[39m,\u001b[38;5;241m23.0\u001b[39m,\u001b[38;5;241m28.7\u001b[39m,\u001b[38;5;241m34.6\u001b[39m,\u001b[38;5;241m40.4\u001b[39m,\u001b[38;5;241m44.2\u001b[39m] \u001b[38;5;66;03m# Ground Truth call times\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m aud,sr \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mML_SR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile Samples:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mshape(aud)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Rate:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m aud \u001b[38;5;241m=\u001b[39m aud[startT\u001b[38;5;241m*\u001b[39msr:endT\u001b[38;5;241m*\u001b[39msr]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\internship1\\Lib\\site-packages\\librosa\\core\\audio.py:184\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPurePath)):\n\u001b[0;32m    181\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    183\u001b[0m     )\n\u001b[1;32m--> 184\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__audioread_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\internship1\\Lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\internship1\\Lib\\site-packages\\librosa\\util\\decorators.py:59\u001b[0m, in \u001b[0;36mdeprecated.<locals>.__wrapper\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Warn the user, and then proceed.\"\"\"\u001b[39;00m\n\u001b[0;32m     51\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mDeprecated as of librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mIt will be removed in librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# Would be 2, but the decorator adds a level\u001b[39;00m\n\u001b[0;32m     58\u001b[0m )\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\internship1\\Lib\\site-packages\\librosa\\core\\audio.py:240\u001b[0m, in \u001b[0;36m__audioread_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    237\u001b[0m     reader \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m     reader \u001b[38;5;241m=\u001b[39m \u001b[43maudioread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader \u001b[38;5;28;01mas\u001b[39;00m input_file:\n\u001b[0;32m    243\u001b[0m     sr_native \u001b[38;5;241m=\u001b[39m input_file\u001b[38;5;241m.\u001b[39msamplerate\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\internship1\\Lib\\site-packages\\audioread\\__init__.py:127\u001b[0m, in \u001b[0;36maudio_open\u001b[1;34m(path, backends)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m BackendClass \u001b[38;5;129;01min\u001b[39;00m backends:\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBackendClass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m DecodeError:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\internship1\\Lib\\site-packages\\audioread\\rawread.py:59\u001b[0m, in \u001b[0;36mRawAudioFile.__init__\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m aifc\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\CloudData\\\\2024\\\\Nepal\\\\ML001\\\\20h00.wav'"
     ]
    }
   ],
   "source": [
    "filename = \"C:\\\\CloudData\\\\2024\\\\Nepal\\\\ML001\\\\20h00.wav\"\n",
    "\n",
    "startT = 493 # Time in seconds to extract a useful clip from\n",
    "endT = 539\n",
    "gtT = [1.0,12.4,23.0,28.7,34.6,40.4,44.2] # Ground Truth call times\n",
    "\n",
    "aud,sr = librosa.load(filename,sr=ML_SR)\n",
    "print(f\"File Samples:{np.shape(aud)}, Rate:{sr}\")\n",
    "aud = aud[startT*sr:endT*sr]\n",
    "print(f\"Clipped Samples:{np.shape(aud)}, Rate:{sr}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1:\n",
    "\n",
    "Convert the wav file to FFT. We then extract out our \"feature map\" which is just the spectral magnitude bins. We do a simple boxcar aggregate, but we could use a triangular weighting quite easily as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunkToBins(chunk,fLo,fHi,numbins,sr):\n",
    "    \"\"\"convert a chunk (window) to slope.\n",
    "    Provide the low and high frequencies in Hz for a spectral windowing\n",
    "    numbins are the number of output bins between flo and fhi\n",
    "    Provide the sample rate in Hz\"\"\"\n",
    "    CMPLX_FFT_LEN = len(chunk)*2\n",
    "    \n",
    "    fS = np.fft.fft(chunk,n=CMPLX_FFT_LEN) # fft - note we double it for the cmplx fft\n",
    "    fRes = sr/(CMPLX_FFT_LEN)   # frequency per cmplx bin\n",
    "    #print(fRes)\n",
    "    binLo = int(fLo/sr*CMPLX_FFT_LEN)\n",
    "    binHi = int(fHi/sr*CMPLX_FFT_LEN)\n",
    "    specSize = int((binHi-binLo)/numbins)\n",
    "    binTotals = np.zeros(numbins)\n",
    "    for k in range(numbins):\n",
    "        dbSum = 0\n",
    "        for j in range(specSize):\n",
    "            idx = binLo + (k * numbins) + j\n",
    "            dbVal = np.log10(np.abs(fS[idx]))\n",
    "            dbSum += dbVal\n",
    "        binTotals[k] = dbSum\n",
    "    return binTotals\n",
    "q = chunkToBins(aud[:SPECD_FFT_LEN],ML_FLO,ML_FHI,ML_BIN_AGG,ML_SR)\n",
    "print(q)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Make a template\n",
    "\n",
    "Here we just use an arbitrary call to build a template. We could do much better with average calls etc. We scale the template so it is zero-mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tList = []\n",
    "idxStart = 718\n",
    "idxEnd = 730\n",
    "for idx in range(int(idxStart*ML_FFT_STRIDE),int(idxEnd*ML_FFT_STRIDE),int(ML_FFT_STRIDE)):\n",
    "    clip = aud[idx:idx+SPECD_FFT_LEN]\n",
    "    q = chunkToBins(clip,ML_FLO,ML_FHI,ML_BIN_AGG,ML_SR)\n",
    "    tList.append(q)\n",
    "print(len(tList))\n",
    "tList = np.array(tList)\n",
    "\n",
    "print(np.min(tList),np.max(tList))\n",
    "# Thresholding\n",
    "if THRESHOLDED:\n",
    "    tList = (tList >0)*tList\n",
    "# Scale the dB mag spec to +1/-1\n",
    "tList = (tList-np.min(tList))\n",
    "tList = (tList-np.max(tList)/2)\n",
    "#tList = tList/np.max(tList)\n",
    "#tList = tList *2.0 -1.0\n",
    "print(np.min(tList),np.max(tList))\n",
    "\n",
    "pylab.imshow(tList.T,aspect=10)\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Slide the window and correlate\n",
    "\n",
    "We manually compute the correlation, so it is directly the same as our high-tech C code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "qList = []\n",
    "for idx in range(0,len(aud),int(ML_FFT_STRIDE)):\n",
    "    clip = aud[idx:idx+SPECD_FFT_LEN]\n",
    "    q = chunkToBins(clip,ML_FLO,ML_FHI,ML_BIN_AGG,ML_SR)\n",
    "    \n",
    "    qList.append(q)\n",
    "qList = np.array(qList)\n",
    "# Now we cross correlate\n",
    "print(np.shape(qList),np.shape(tList))\n",
    "xcorr = []\n",
    "for offset in range(len(qList)-np.shape(tList)[0]):\n",
    "    xcTotal = 0\n",
    "    for tIdx in range(np.shape(tList)[0]):\n",
    "        for bIdx in range(ML_BIN_AGG):\n",
    "            xcTotal += qList[offset+tIdx][bIdx]*tList[tIdx][bIdx]\n",
    "    xcorr.append(xcTotal)\n",
    "xcorr = np.array(xcorr)\n",
    "\n",
    "\n",
    "print(np.shape(xcorr))\n",
    "\n",
    "\n",
    "pylab.subplot(311)\n",
    "pylab.imshow(qList.T,aspect=50)\n",
    "pylab.xlim(0,len(qList))\n",
    "pylab.subplot(312)\n",
    "pylab.specgram(aud,Fs=8000,NFFT=1024,noverlap=800)\n",
    "pylab.ylim(800,1400)\n",
    "pylab.scatter(gtT,np.ones(len(gtT))*1000,c='red',marker='*',s=80)\n",
    "pylab.subplot(313)\n",
    "pylab.plot((xcorr))\n",
    "pylab.xlim(0,len(xcorr))\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Peak Detection\n",
    "\n",
    "This is loosely based on https://stackoverflow.com/questions/22583391/peak-signal-detection-in-realtime-timeseries-data/54507140#54507140\n",
    "\n",
    "But made simpler to work neatly on the MCU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIN_LENGTH = 15\n",
    "WIN_HOP = 1\n",
    "WIN_THRESHOLD = 8.0\n",
    "WIN_ALPHA = 0.00025\n",
    "INIT_WINDEV = 10.0\n",
    "WIN_ALPHA_MEAN = 0.1\n",
    "\n",
    "dets = []\n",
    "scaled_vals = []\n",
    "for k in range(WIN_LENGTH):\n",
    "        dets.append(0)\n",
    "        scaled_vals.append(0)\n",
    "\n",
    "winDev=INIT_WINDEV\n",
    "alpha = WIN_ALPHA\n",
    "alpha_mean = WIN_ALPHA_MEAN\n",
    "winMean = np.mean(xcorr[:WIN_LENGTH]) # initialize\n",
    "for idx in range(0,len(xcorr)-WIN_LENGTH,WIN_HOP):\n",
    "    # This is our circular window\n",
    "    extract = np.array(xcorr[idx:idx+WIN_LENGTH])\n",
    "    winDev = (alpha*np.std(extract)) + (1-alpha)*winDev\n",
    "    winMean = (alpha_mean*np.mean(extract))+(1-alpha_mean)*winMean\n",
    "    det = 0\n",
    "    if (extract[-1] -winMean)/winDev > WIN_THRESHOLD:\n",
    "        det = 1\n",
    "    scaled_vals.append((extract[-1] -winMean)/winDev)\n",
    "    dets.append(det)\n",
    "pylab.subplot(311)\n",
    "pylab.plot(xcorr)\n",
    "pylab.subplot(312)\n",
    "pylab.plot(scaled_vals)\n",
    "pylab.subplot(313)\n",
    "pylab.plot(dets)\n",
    "\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Export Template to C\n",
    "\n",
    "And now we can dump all these parameters into a header file so that we can easily adjust things on the PC, and they will automagically update the caracal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "CMPLX_FFT_LEN = SPECD_FFT_LEN*2\n",
    "binLo = int(ML_FLO/ML_SR*CMPLX_FFT_LEN)\n",
    "binHi = int(ML_FHI/ML_SR*CMPLX_FFT_LEN)\n",
    "specSize = int((binHi-binLo)/ML_BIN_AGG)\n",
    "DATECODE = datetime.datetime.now()\n",
    "\n",
    "print(\"#ifndef SPEC_DETECT_TEMPLATE_H\")\n",
    "print(\"#define SPEC_DETECT_TEMPLATE_H\")\n",
    "print(\"// AUTOGENERATED PARAMETERS FROM CARACALRT>EvoRT_004>TEMPLATEMAKER003.IPYNB\")\n",
    "print(f\"// TIMESTAMP:{DATECODE}\")\n",
    "print(\"\")\n",
    "print(\"// Sampling Rate:\")\n",
    "print(f\"const uint32_t SPECD_SR = {ML_SR};\")\n",
    "print(\"// FFT Size (REAL), single sided - equivalent to 1/2 length of a complex FFT:\")\n",
    "print(f\"const uint32_t SPECD_FFT_LEN = {SPECD_FFT_LEN};\")\n",
    "print(\"// FFT Stride:\")\n",
    "print(f\"const uint32_t SPECD_FFT_STRIDE = {ML_FFT_STRIDE};\")\n",
    "print(\"// Number of bins in template/cross-correlation:\")\n",
    "print(f\"const uint32_t SPECD_XC_NUM_BINS = {ML_BIN_AGG};\")\n",
    "print(\"// Bin index for low frequency (NB: Double this to get the unpacked index into the FFT array)\")\n",
    "print(f\"const uint32_t SPECD_FFT_BIN_LO = {binLo};\")\n",
    "print(\"// Bin index for high frequency (NB: Double this to get the unpacked index into the FFT array)\")\n",
    "print(f\"const uint32_t SPECD_FFT_BIN_HI = {binHi};\")\n",
    "print(\"// How many FFT bins to aggregate into one XC bin\")\n",
    "print(f\"const uint32_t SPECD_SPEC_SIZE = {specSize};\")\n",
    "print(\"// How many FFTs to stack for cross correlation\")\n",
    "print(f\"const uint32_t SPECD_NUM_FFT_STRIDES = {np.shape(tList)[0]};\")\n",
    "print(\"// Threshold for peak detection (number of standard deviations)\")\n",
    "print(f\"const float32_t SPECD_XC_THRESHOLD = {WIN_THRESHOLD};\")\n",
    "print(\"// Number of samples in sliding window for peak detection\")\n",
    "print(f\"const uint32_t SPECD_XC_BUF_LEN = {WIN_LENGTH};\")\n",
    "print(\"// Smoothing rate in the window\")\n",
    "print(f\"const float32_t SPECD_XC_WIN_ALPHA = {WIN_ALPHA};\")\n",
    "print(\"// Initial Window SD value\")\n",
    "print(f\"const float32_t SPECD_XC_WIN_SDINIT = {INIT_WINDEV};\")\n",
    "print(\"// Smoothing factor for mean\")\n",
    "print(f\"const float32_t SPECD_XC_WIN_ALPHA_MEAN = {WIN_ALPHA_MEAN};\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"// XC template\")\n",
    "print(f\"const float32_t SPECD_template [{np.shape(tList)[0]}] [{np.shape(tList)[1]}] = {{\")\n",
    "for k in range(np.shape(tList)[0]):\n",
    "    print(\"\\t{\")\n",
    "    for j in range(np.shape(tList)[1]):\n",
    "        if (j<np.shape(tList)[1]-1):\n",
    "            print(\"\\t\",tList[k][j],\",\")\n",
    "        else:\n",
    "            print(\"\\t\",tList[k][j])\n",
    "    if (k<np.shape(tList)[0]-1):\n",
    "        print(\"\\t},\")\n",
    "    else:\n",
    "        print(\"\\t}\")\n",
    "print(\"};\")\n",
    "print(\"#endif\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Export template to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "templateObj = {}\n",
    "templateObj[\"DateCode\"]=DATECODE\n",
    "templateObj['tList']=tList\n",
    "templateObj['ML_SR']=ML_SR\n",
    "templateObj['SPECD_FFT_LEN']=SPECD_FFT_LEN\n",
    "templateObj['ML_BIN_AGG']=ML_BIN_AGG\n",
    "templateObj['ML_FLO']=ML_FLO\n",
    "templateObj['ML_FHI']=ML_FHI\n",
    "templateObj['ML_FFT_STRIDE']=ML_FFT_STRIDE\n",
    "templateObj['WIN_LENGTH']=WIN_LENGTH\n",
    "templateObj[\"WIN_ALPHA\"]=WIN_ALPHA\n",
    "templateObj[\"INIT_WINDEV\"]=INIT_WINDEV\n",
    "templateObj[\"WIN_ALPHA_MEAN\"]=WIN_ALPHA_MEAN\n",
    "with open(FILEPREFIX+\".pkl\",'wb') as f:\n",
    "    pickle.dump(templateObj,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
