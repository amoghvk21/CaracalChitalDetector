{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML004.01: Annotation Aggregation\n",
    "\n",
    "This script ingests .txt files corresponding to Raven annotations of chital deer and assembles them into a single pandas dataframe for dataset extraction/analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "from zoneinfo import ZoneInfo # we sometimes get weird timezones if we use pytz\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#root_paths = [\"C:\\\\CloudData\\\\2024\\\\Nepal\\\\N001\\\\Annotations\"]\n",
    "root_paths = [\"C:\\\\Users\\\\Amogh\\\\OneDrive - University of Cambridge\\\\Programming-New\\\\CaracalChitalDetector\\\\cnn\\\\annotations\"]\n",
    "#root_paths = [\"C:\\\\Users\\\\Amogh\\\\OneDrive - University of Cambridge\\\\Programming-New\\\\CaracalChitalDetector\\\\data\\\\Test set\\\\1 hour files\"]\n",
    "annotation_timezone = \"UTC\" # timezone of the annotation data itself\n",
    "output_timezone = \"UTC\" # We want everything to be UTC for consistency\n",
    "input_extension = \".txt\"\n",
    "annotation_type = \"Acoustic\" # \n",
    "TimeFormat = '%Y%m%d$%H%M%S' # format of datecode in the input file\n",
    "outputfile = \"AcousticAnnotations001.pb\" # Contains only 2024 files\n",
    "outputfile_all = \"all_annotations.pb\"  # Contains 2023 and 2024 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1:\n",
    "Crawl the directory/directories and find all the individual files. We assume any .txt file is a raven annotation file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 26 annotation files\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for root_path in root_paths:\n",
    "    result += [os.path.join(dp, f) for dp, dn, filenames in os.walk(root_path) for f in filenames if os.path.splitext(f)[1] == input_extension]\n",
    "print(\"loaded\",len(result),\"annotation files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amogh\\OneDrive - University of Cambridge\\Programming-New\\CaracalChitalDetector\\cnn\\annotations\\CAR204_20240323$135900_1711181640.Table.1.selections.txt\n",
      "['CAR204', '20240323$135900', '1711181640']\n",
      "2024-03-23 13:59:00\n"
     ]
    }
   ],
   "source": [
    "print(result[0])\n",
    "full_filename=result[0]\n",
    "fields = os.path.split(full_filename)[1].split(\".\")[0].split(\"_\")\n",
    "print(fields)\n",
    "\n",
    "filedt = datetime.datetime.strptime(fields[1],TimeFormat)\n",
    "print(filedt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2:\n",
    "\n",
    "Parse each file and cat onto a common dataframe. We need to take into account:\n",
    "\n",
    "1. The datetime of the source file. This is because all the annotations are relative to this within the file\n",
    "2. The station ID. This gives us the (semantic) location of the extracted sounds. \n",
    "\n",
    "We then export the whole pandas dataframe to a pickled object so we can query/parse it rapidly in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved a total of  1346 annotations\n"
     ]
    }
   ],
   "source": [
    "dictlist = []\n",
    "\n",
    "for full_filename in result:\n",
    "    \n",
    "    try:\n",
    "        fields = os.path.split(full_filename)[1].split(\".\")[0].split(\"_\")\n",
    "        station_id = fields[0]\n",
    "        filestrdt = fields[1]\n",
    "        filebasetime = fields[2]\n",
    "        filedt = datetime.datetime.strptime(filestrdt,TimeFormat)\n",
    "        localdt = filedt.replace(tzinfo=ZoneInfo(annotation_timezone))\n",
    "        rootdt = localdt.astimezone(ZoneInfo(output_timezone))\n",
    "    except:\n",
    "        print(\"Invalid file pattern\",full_filename)\n",
    "        pass\n",
    "    try:\n",
    "        df = pd.read_csv(full_filename,sep=\"\\t\")\n",
    "    except:\n",
    "        print(\"Issue with reading file:\",full_filename)\n",
    "    for idx,row in df.iterrows():\n",
    "        try:\n",
    "            rowdict = {}\n",
    "            rowdict['LocationName'] = station_id\n",
    "            rowdict['SourceFile'] = full_filename\n",
    "            rowdict['AnnotationType'] = annotation_type\n",
    "            rowdict['RelativeStartTime'] = datetime.timedelta(seconds=row['Begin Time (s)'])\n",
    "            rowdict['RelativeEndTime'] = datetime.timedelta(seconds=row['End Time (s)'])\n",
    "            rowdict['StartTime'] = rootdt+datetime.timedelta(seconds=row['Begin Time (s)'])\n",
    "            rowdict['EndTime'] = rootdt+datetime.timedelta(seconds=row['End Time (s)'])\n",
    "            rowdict['FileStartTime']=filedt\n",
    "            rowdict['LowFreq'] = row['Low Freq (Hz)']\n",
    "            rowdict['HighFreq'] = row['High Freq (Hz)']\n",
    "            if 'Annotation' in df.columns:\n",
    "                rowdict['Annotation']= str(row['Annotation'])\n",
    "            elif 'Annotations' in df.columns:\n",
    "                rowdict['Annotation']= str(row['Annotations'])\n",
    "            elif 'Annotate' in df.columns:\n",
    "                rowdict['Annotation']= str(row['Annotate'])\n",
    "            elif 'Species' in df.columns:\n",
    "                rowdict['Annotation']= str(row['Species'])\n",
    "            elif 'type' in df.columns:\n",
    "                rowdict['Annotation']= str(row['type'])\n",
    "            else:\n",
    "                print(\"Skipping row\",idx,row,full_filename)\n",
    "                continue\n",
    "            dictlist.append(rowdict)\n",
    "        except:\n",
    "            print(\"Issue with parsing row\",idx,row,full_filename)\n",
    "\n",
    "# we can now turn our list of dicts back into a dataframe\n",
    "outputdf = pd.DataFrame(dictlist)\n",
    "# and export it into nice formats that can easily be reloaded/parsed\n",
    "print(\"retrieved a total of \",len(outputdf),\"annotations\")\n",
    "with open(outputfile,'wb') as handle:\n",
    "    pickle.dump(outputdf,handle)\n",
    "\n",
    "outputdf.to_csv(\"AcousticAnnotations001.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Reload and verify\n",
    "\n",
    "Reload the annotation dataframe to check that it is correct and useful for downstream tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataframe with 1346 annotations.\n"
     ]
    }
   ],
   "source": [
    "with open(outputfile,'rb') as handle:\n",
    "    reloadDF = pickle.load(handle)\n",
    "print(f\"Loaded dataframe with {len(reloadDF)} annotations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Distribution of annotations\n",
    "\n",
    "Here we look through the whole set of annotations and look at the count of each type of annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'C': 852, 'O': 409, 'M': 82, 'nan': 2, '#': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pprint\n",
    "annotation_list = reloadDF['Annotation'].tolist()\n",
    "counts = Counter(annotation_list)\n",
    "pprint.pprint(counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
